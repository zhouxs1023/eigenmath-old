\magnification=1200
\parindent=0pt

\beginsection{December 24, 2002}

14.1(a) $\sum n^4/2^n$ Try the ratio test.
\medskip
$\displaystyle{
{a_{n+1}\over a_n}
={(n+1)^4/2^{n+1}\over n^4/2^n}
={(n+1)^4\over2^{n+1}}\times{2^n\over n^4}
={(n+1)^4\over2n^4}\rightarrow{1\over2}<1}$
\medskip
So by the ratio test $\sum n^4/2^n$ converges.

\bigskip

14.1(b) $\sum2^n/n!$ Try the ratio test.
\medskip
$\displaystyle{{a_{n+1}\over a_n}={2^{n+1}/(n+1)!\over 2^n/n!}
={2^{n+1}\over(n+1)!}\times{n!\over2^n}={2\over n+1}<1}$
\medskip
So by the ratio test $\sum2^n/n!$ converges.

\bigskip

14.1(c) $\sum n^2/3^n$ Try the ratio test.
\medskip
$\displaystyle{
{a_{n+1}\over a_n}
={(n+1)^2/3^{n+1}\over n^2/3^n}
={(n+1)^2\over 3^{n+1}}\times{3^n\over n^2}
={(n+1)^2\over3n^2}\rightarrow{1\over3}<1
}$
\medskip
So by the ratio test $\sum n^2/3^n$ converges.

\bigskip

14.1(d) $\sum n!/(n^4+3)$ Try the ratio test.
\medskip
$\displaystyle{
{a_{n+1}\over a_n}
={(n+1)!/((n+1)^4+3)\over n!/(n^4+3)}
={(n+1)!\over((n+1)^4+3)}\times{n^4+3\over n!}
\rightarrow n+1>1
}$
\medskip
So by the ratio test $\sum n!/(n^4+3)$ diverges.

\bigskip

14.1(e) $\sum\cos^2 n/n^2$ Use the comparison test.
Since $\sum1/n^2$ converges and
$|\cos^2 n/n^2|\le1/n^2$ for all $n$, $\sum\cos^2 n/n^2$ must also converge.

\bigskip

14.1(f) $\sum_{n=2}^\infty1/(\log n)$ Use the comparison test.
Since $\sum(1/n)$ diverges and $1/(\log n)>1/n$ for all $n>1$,
$\sum_{n=2}^\infty1/(\log n)$ must also diverge.

\beginsection{December 26, 2002}

Zeno's Paradox: The solution is that the infinite sum converges.

\bigskip

Proof of the Root Test. Let $\alpha=\lim\sup|a_n|^{1/n}$.
We can select an $\epsilon$ so that $\lim\sup|a_n|^{1/n}<\alpha+\epsilon$.
Next we can move the exponent around and put $|a_n|=(\alpha+\epsilon)^n$.
Now if $\alpha<1$ then we can choose a suitably small $\epsilon$ so that
$\alpha+\epsilon<1$. Since the geometric series $\sum(\alpha+\epsilon)^n$
converges, $\sum a_n$ must converge by the Comparison Test.
So if $\alpha<1$ then $\sum a_n$ converges.

\bigskip

Even simpler: If $\alpha<1$ then $\sum \alpha^n$ converges
and so $\sum a_n$ converges by the Comparison Test.

\bigskip

14.2(a) $\sum(n-1)/n^2$. Try the ratio test.
\medskip
$\displaystyle{
{a_{n+1}\over a_n}
={n\over(n+1)^2}\times{n^2\over n-1}
={n^3\over n^3+n^2-n-1}<1?
}$
\medskip
Not so sure. It gets closer and closer to 1 so is $\lim\sup=1$?
If we consider $\sum(n-1)/n^2=\sum(1/n-1/n^2)$ it looks divergent.
Is it fair to say that since
\medskip
$\displaystyle{\lim\sup{n^3+n^2-n-1\over n^3}=1}$ that
$\displaystyle{\lim\sup{n^3\over n^3+n^2-n-1}=1}$ also?

\bigskip

14.2(b) $\sum(-1)^n$ The sum is 0 for even $n$ and $-1$ for odd $n$.
So it does not converge but it is bounded.

\bigskip

14.2(c) $\sum3n/n^3$ This is the same as $\sum3/n^2$ which converges.
(Can't find the theorem that says if $\sum a_n$ converges then
$r\sum a_n$ also converges.)

\bigskip

14.2(d) $\sum n^3/3^n$ Try the ratio test.
\medskip
$\displaystyle{
{a_{n+1}\over a_n}
={(n+1)^3\over3^{n+1}}\times{3^n\over n^3}
\rightarrow{1\over3^n}<1
}$ so it converges.

\bigskip

14.2(e) $\sum n^2/n!$ Try the ratio test.
\medskip
$\displaystyle{
{a_{n+1}\over a_n}
={(n+1)^2\over(n+1)!}\times{n!\over n^2}
\rightarrow{1\over n+1}<1}$ so it converges.

\bigskip

14.2(f) $\sum1/n^n$ Converges by the Comparison test since $1/n^n<1/n^2$.

\bigskip

14.2(g) $\sum n/2^n$ Try the ratio test.
\medskip
$\displaystyle{
{a_{n+1}\over a_n}
={n+1\over2^{n+1}}\times{2^n\over n}
\rightarrow{1\over2}<1}$ so it converges.

\bigskip

14.3(a) $\sum1/\sqrt{n!}$ Try the ratio test.
\medskip
$\displaystyle{
{a_{n+1}\over a_n}
={1\over\sqrt{(n+1)!}}\times{\sqrt{n!}\over1}
={1\over\sqrt{n+1}\cdot\sqrt{n!}}\times{\sqrt{n!}\over1}
={1\over\sqrt{n+1}}<1}$ so it converges.

\beginsection{December 27, 2002}

Question: $\sum1/n$ seems to satisfy the Cauchy criterion.
For every $\epsilon$ there is an $n$ such that $1/n<\epsilon$.
But $\sum1/n$ does not converge.
What am I missing?
Ok, I think I see the problem.
The Cauchy criterion is
$|\sum_{k=m}^n a_k|<\epsilon$ for {\it all} values of $n\ge m>N$.
Consider the case where $m=N+1$ and $n=+\infty$.
In this case we have to add up
all the terms all the way out to infinity and have it come up less than
$\epsilon$.

\bigskip

Question about
$\displaystyle{\lim{n^3\over n^3+n^2-n-1}=1?}$
Solution: Multiply through by $1/n^3$:
\medskip
$\displaystyle{
\lim{n^3\over n^3+n^2-n-1}
=\lim{1\over1+{1\over n}-{1\over n^2}-{1\over n^3}}
=\lim{1\over1+0+0+0}=1
}$

\beginsection{December 30, 2002}

Page 89, example 1. Show that $f(x)=2x^2+1$ is continuous using the
$\epsilon$-$\delta$ property.
We want to show that $|f(x)-f(x_0)|<\epsilon$ when $|x-x_0|<\delta$.
Start by evaluating $|f(x)-f(x_0)|$ as follows:
\medskip
$\displaystyle{
|f(x)-f(x_0)|=|2x^2+1-(2x_0^2+1)|=|2x^2-2x_0^2|=2|x-x0|\cdot|x+x_0|
}$
\medskip
Ok, I get that, except for maybe the last step that distributes the absolute
value function. The book says, ``We need to get a bound for $|x+x_0|$ that
does not depend on $x$.'' Why?
Well, I think basically it's to get rid of $x^2$, to have a relation that's
linear in $x$.
Ok, onwards. Consider the case of $\delta<1$ which seems pretty typical
since $\delta$ is allowed to get infinitely small.
So $\delta<1$ means that $|x-x_0|<1$.
Now watch this. The book says this means that $|x|<|x_0|+1$.
It's true and here is why.
Suppose $|x|$ is already less than $|x_0|$.
Then it is certainly less than $|x_0|+1$.
Now suppose $|x|$ is greater than $|x_0|$.
Then by $\delta<1$ the difference has to be less than 1.
(I'm impressed by the creativity here. Or is this a common trick to use?)
So now that we have $|x|<|x_0|+1$, then we can put
$|x+x_0|\le|x|+|x_0|<2|x_0|+1$. Whew!
(How? By the triangle inequality and then by adding $|x_0|$ to both sides
of $|x|<|x_0|+1$.)
Now that we have $|x+x_0|<2|x_0|+1$ we can put
\medskip
$\displaystyle{
|f(x)-f(x_0)|<2|x-x_0|(2|x_0|+1)
}$
\medskip
with the caveat $\delta<1$.
Now we want $2|x-x_0|(2|x_0|+1)<\epsilon$ which leads to
\medskip
$\displaystyle{
|x-x_0|<{\epsilon\over2(2|x_0|+1)}
}$
\medskip
Since $|x-x_0|<\delta$ we can choose the following $\delta$:
\medskip
$\displaystyle{
\delta={\epsilon\over2(2|x_0|+1)}
}$
\medskip
and since $\delta<1$ we have
\medskip
$\displaystyle{
\delta=\min\left\{1,{\epsilon\over2(2|x_0|+1)}\right\}
}$
\medskip
This final relation shows that $|x-x_0|<\delta$ implies
$|f(x)-f(x_0)|<\epsilon$, which is what we wanted in the first place.
(Really? How?)

\beginsection{December 31, 2002}

From yesterday: $|x^2-x_0^2|=|x-x_0|\times|x+x_0|$. How?
First, factor it: $x^2-x_0^2=(x-x_0)(x+x_0)$.
Then apply the identity $|AB|=|A|\times|B|$.

\end
